<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>一步步完善视觉里程计3——初始位置确定 | Blackant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前面一篇博客，我们已经进行了特征提取，前面我们也说了，我们接下来不是通过特征匹配的方式来寻找对应特征点，而是采用跟踪的方式。&amp;lt;/br&amp;gt;在前面视觉里程计总述中讲诉了误差的累计，因此初始位置的确定显得尤为重要，要确保初始位置的尽可能的准确。这一篇博客主要讲述了如何更精确的确定初始位置。">
<meta property="og:type" content="article">
<meta property="og:title" content="一步步完善视觉里程计3——初始位置确定">
<meta property="og:url" content="http://yoursite.com/2017/09/18/一步步完善视觉里程计3——初始位置确定/index.html">
<meta property="og:site_name" content="Blackant">
<meta property="og:description" content="前面一篇博客，我们已经进行了特征提取，前面我们也说了，我们接下来不是通过特征匹配的方式来寻找对应特征点，而是采用跟踪的方式。&amp;lt;/br&amp;gt;在前面视觉里程计总述中讲诉了误差的累计，因此初始位置的确定显得尤为重要，要确保初始位置的尽可能的准确。这一篇博客主要讲述了如何更精确的确定初始位置。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://7xl6tk.com1.z0.glb.clouddn.com/findHomography.png">
<meta property="og:image" content="http://7xl6tk.com1.z0.glb.clouddn.com/initial_position.png">
<meta property="og:updated_time" content="2019-02-21T08:49:15.529Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一步步完善视觉里程计3——初始位置确定">
<meta name="twitter:description" content="前面一篇博客，我们已经进行了特征提取，前面我们也说了，我们接下来不是通过特征匹配的方式来寻找对应特征点，而是采用跟踪的方式。&amp;lt;/br&amp;gt;在前面视觉里程计总述中讲诉了误差的累计，因此初始位置的确定显得尤为重要，要确保初始位置的尽可能的准确。这一篇博客主要讲述了如何更精确的确定初始位置。">
<meta name="twitter:image" content="http://7xl6tk.com1.z0.glb.clouddn.com/findHomography.png">
  
    <link rel="alternate" href="/atom.xml" title="Blackant" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Blackant</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-一步步完善视觉里程计3——初始位置确定" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/18/一步步完善视觉里程计3——初始位置确定/" class="article-date">
  <time datetime="2017-09-18T12:09:26.000Z" itemprop="datePublished">2017-09-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      一步步完善视觉里程计3——初始位置确定
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>前面一篇博客，我们已经进行了特征提取，前面我们也说了，我们接下来不是通过特征匹配的方式来寻找对应特征点，而是采用跟踪的方式。&lt;/br&gt;<br>在前面视觉里程计总述中讲诉了误差的累计，因此初始位置的确定显得尤为重要，要确保初始位置的尽可能的准确。这一篇博客主要讲述了如何更精确的确定初始位置。</strong><a id="more"></a></p>
<h2 id="sophus库的添加"><a href="#sophus库的添加" class="headerlink" title="sophus库的添加"></a>sophus库的添加</h2><p>对于<strong>sophus</strong>，目前我理解的范围就是对旋转和平移做了一个封装，可以更好的进行刚性变换。为了更方便的看懂，这里使用了<strong>sophus</strong>的非模板的版本，通过<em>git clone <a href="https://github.com/strasdat/Sophus.git" target="_blank" rel="noopener">https://github.com/strasdat/Sophus.git</a></em>后继续<em>git checkout a621ff</em>&lt;/br&gt;<br>这边编译在vs2013上报错，在文件so2.cpp中，修改如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SO2::SO2()</span><br><span class="line">&#123;</span><br><span class="line">//unit_complex_.real() = 1.;</span><br><span class="line">//unit_complex_.imag() = 0.;</span><br><span class="line">unit_complex_.real(1.);	</span><br><span class="line">unit_complex_.imag(0.);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>对于李群李代数后续需进一步学习。</strong></p>
<h2 id="初始位置确定"><a href="#初始位置确定" class="headerlink" title="初始位置确定"></a>初始位置确定</h2><p>初始位置的确定的基本思路，根据光流确定对应特征点，根据对应特征点计算两帧之间的单应矩阵，根据单应矩阵进行分解，计算出两帧之间的旋转和平移。&lt;/br&gt;<br>考虑到帧的旋转和平移，则在帧上添加属性,添加从世界坐标系(w)orld转到摄像机坐标系(f)rame的刚性变换<strong>Rt Sophus::SE3 Tf_w;</strong>，而对于特征添加特征对应的3D点，以及特征的单位方向向量（用于后期的三角定位），具体添加如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Vector3d f;           //!&lt; 特征的单位方向向量</span><br><span class="line">Point3D* point;       //!&lt; 指针指向跟特征对应的3D点</span><br></pre></td></tr></table></figure>
<p>这里我们构建Point3D这个类，用于表示特征所对应的3D点，具体定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Point3D : Noncopyable</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">EIGEN_MAKE_ALIGNED_OPERATOR_NEW</span><br><span class="line"></span><br><span class="line">Point3D(const Vector3d&amp; pos);</span><br><span class="line">~Point3D();</span><br><span class="line">/// 添加特征到一个帧中</span><br><span class="line">void addFrameRef(Feature* ftr);</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">static int    point_counter_; //!&lt; 创建点的计数，用于设置唯一的id</span><br><span class="line">int           id_;            //!&lt; 点唯一的id</span><br><span class="line">Vector3d      pos_;           //!&lt; 点在世界坐标系中的位置</span><br><span class="line">std::list&lt;Feature*&gt;   obs_;   //!&lt; 对应这个点的特征</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>这样新的数据结构就修改和添加完成，我们接下来要做的事情就是进行整合。</p>
<h2 id="选择第一帧"><a href="#选择第一帧" class="headerlink" title="选择第一帧"></a>选择第一帧</h2><p>为了更好的确定初始位置，我们对第一帧的选择有一定的限制条件，我们要确保第一帧的图像中检测到的特征数大于100个。只有满足这样的条件，我们可以方便的进行下一步的特征跟踪，具体实现如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">InitResult Initialization::addFirstFrame(FramePtr frame_ref)</span><br><span class="line">&#123;</span><br><span class="line">reset();</span><br><span class="line">detectFeatures(frame_ref, px_ref_, f_ref_);</span><br><span class="line">if (px_ref_.size() &lt; 100)</span><br><span class="line">&#123;</span><br><span class="line">std::cerr &lt;&lt; &quot;First image has less than 100 features. Retry in more textured environment.&quot; &lt;&lt; std::endl;</span><br><span class="line">return FAILURE;</span><br><span class="line">&#125;</span><br><span class="line">// 将这一帧图像做为参考帧</span><br><span class="line">frame_ref_ = frame_ref;</span><br><span class="line">// 先设置当前帧的特征与参考帧的特征一致</span><br><span class="line">px_cur_.insert(px_cur_.begin(), px_ref_.begin(), px_ref_.end());</span><br><span class="line">return SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这边根据当前帧可以检测到特征点的位置，以及获得特征的单位向量，具体可以参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">/// 检测fast角度，输出的是对应的点和点的方向向量（可以考虑为点的反投影坐标）</span><br><span class="line">void Initialization::detectFeatures(</span><br><span class="line">FramePtr frame,</span><br><span class="line">std::vector&lt;cv::Point2f&gt;&amp; px_vec,</span><br><span class="line">std::vector&lt;Vector3d&gt;&amp; f_vec)</span><br><span class="line">&#123;</span><br><span class="line">Features new_features;</span><br><span class="line">FastDetector detector(</span><br><span class="line">frame-&gt;img().cols, frame-&gt;img().rows, 25, 3);</span><br><span class="line">detector.detect(frame.get(), frame-&gt;img_pyr_, 20.0, new_features);</span><br><span class="line"></span><br><span class="line">// 返回特征位置和特征的单位向量</span><br><span class="line">px_vec.clear(); px_vec.reserve(new_features.size());</span><br><span class="line">f_vec.clear(); f_vec.reserve(new_features.size());</span><br><span class="line">std::for_each(new_features.begin(), new_features.end(), [&amp;](Feature* ftr)&#123;</span><br><span class="line">px_vec.push_back(cv::Point2f(ftr-&gt;px[0], ftr-&gt;px[1]));</span><br><span class="line">f_vec.push_back(ftr-&gt;f);</span><br><span class="line">delete ftr;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<pre><code>这边有一个疑惑，本来打算对帧frame类中的属性list修改为list,
</code></pre><p>这样就避免了目前对Feature new和delete不在一起的状况。&lt;/br&gt;<br>但是修改之后会报错，报错在对特征对象进行push_back的时候，目前还是仿作者采用指针的方式，后期进行修改。</p>
<h2 id="选择第二帧"><a href="#选择第二帧" class="headerlink" title="选择第二帧"></a>选择第二帧</h2><h2 id="特征跟踪"><a href="#特征跟踪" class="headerlink" title="特征跟踪"></a>特征跟踪</h2><p>第一帧确定好了之后，然后通过金字塔Lucas-Kanade光流方法计算前期特征的光流（稀疏光流），具体使用OpenCV的方法calcOpticalFlowPyrLK，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">void Initialization::trackKlt(</span><br><span class="line">FramePtr frame_ref,</span><br><span class="line">FramePtr frame_cur,</span><br><span class="line">std::vector&lt;cv::Point2f&gt;&amp; px_ref,</span><br><span class="line">std::vector&lt;cv::Point2f&gt;&amp; px_cur,</span><br><span class="line">std::vector&lt;Vector3d&gt;&amp; f_ref,</span><br><span class="line">std::vector&lt;Vector3d&gt;&amp; f_cur,</span><br><span class="line">std::vector&lt;double&gt;&amp; disparities)</span><br><span class="line">&#123;</span><br><span class="line">const double klt_win_size = 30.0;</span><br><span class="line">const int klt_max_iter = 30;</span><br><span class="line">const double klt_eps = 0.001;</span><br><span class="line">std::vector&lt;uchar&gt; status;</span><br><span class="line">std::vector&lt;float&gt; error;</span><br><span class="line">std::vector&lt;float&gt; min_eig_vec;</span><br><span class="line">cv::TermCriteria termcrit(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, klt_max_iter, klt_eps);</span><br><span class="line">cv::calcOpticalFlowPyrLK(frame_ref-&gt;img_pyr_[0], frame_cur-&gt;img_pyr_[0],</span><br><span class="line">px_ref, px_cur,</span><br><span class="line">status, error,</span><br><span class="line">cv::Size2i(klt_win_size, klt_win_size),</span><br><span class="line">4, termcrit, 0);//cv::OPTFLOW_USE_INITIAL_FLOW</span><br><span class="line"></span><br><span class="line">std::vector&lt;cv::Point2f&gt;::iterator px_ref_it = px_ref.begin();</span><br><span class="line">std::vector&lt;cv::Point2f&gt;::iterator px_cur_it = px_cur.begin();</span><br><span class="line">std::vector&lt;Vector3d&gt;::iterator f_ref_it = f_ref.begin();</span><br><span class="line">f_cur.clear(); f_cur.reserve(px_cur.size());</span><br><span class="line">disparities.clear(); disparities.reserve(px_cur.size());</span><br><span class="line">for (size_t i = 0; px_ref_it != px_ref.end(); ++i)</span><br><span class="line">&#123;</span><br><span class="line">if (!status[i])//如果光流没有发现，则删除</span><br><span class="line">&#123;</span><br><span class="line">px_ref_it = px_ref.erase(px_ref_it);</span><br><span class="line">px_cur_it = px_cur.erase(px_cur_it);</span><br><span class="line">f_ref_it = f_ref.erase(f_ref_it);</span><br><span class="line">continue;</span><br><span class="line">&#125;</span><br><span class="line">f_cur.push_back(frame_cur-&gt;c2f(px_cur_it-&gt;x, px_cur_it-&gt;y));//添加当前特征对应的单位向量</span><br><span class="line">disparities.push_back(Vector2d(px_ref_it-&gt;x - px_cur_it-&gt;x, px_ref_it-&gt;y - px_cur_it-&gt;y).norm());//添加对应特征之间的距离</span><br><span class="line">++px_ref_it;</span><br><span class="line">++px_cur_it;</span><br><span class="line">++f_ref_it;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>主要通过跟踪确定下一帧特征的估计位置以及估计特征的单位向量。&lt;/br&gt;<br>而对于跟踪的特征数目要大于50，对于金字塔Lucas-Kanade光流方法的参数调节，后续根据论文及实验进行测试。&lt;/br&gt;<br>在<strong>视觉里程计总述</strong>里面介绍到关键帧，给出图的形式表示两帧的距离很近会影响3D点的准确度。在这里对上述disparities的中值做一个阈值限制，如果其中值小于50，则认为选择的帧不是关键帧，不能进行3D点估计。具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">InitResult Initialization::addSecondFrame(FramePtr frame_cur)</span><br><span class="line">&#123;</span><br><span class="line">trackKlt(frame_ref_, frame_cur, px_ref_, px_cur_, f_ref_, f_cur_, disparities_);</span><br><span class="line">std::cout &lt;&lt; &quot;Init: KLT tracked &quot; &lt;&lt; disparities_.size() &lt;&lt; &quot; features&quot; &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">// 符合光流跟踪的特征数</span><br><span class="line">if (disparities_.size() &lt; 50)</span><br><span class="line">return FAILURE;</span><br><span class="line"></span><br><span class="line">// 对两帧光流跟踪之后像素差值的中值</span><br><span class="line">double disparity = getMedian(disparities_);</span><br><span class="line">std::cout &lt;&lt; &quot;Init: KLT &quot; &lt;&lt; disparity &lt;&lt; &quot;px average disparity.&quot; &lt;&lt; std::endl;</span><br><span class="line">//  如果中值小于给定配置参数，则表明这一帧不是关键帧，也就是刚开始的时候两帧不能太近</span><br><span class="line">if (disparity &lt; 50.0)</span><br><span class="line">return NO_KEYFRAME;</span><br><span class="line">//  计算单应矩阵</span><br><span class="line">computeHomography(</span><br><span class="line">f_ref_, f_cur_,</span><br><span class="line">frame_ref_-&gt;cam_-&gt;getFocalLength(), 2.0,</span><br><span class="line">inliers_, xyz_in_cur_, T_cur_from_ref_);</span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来进行单应矩阵估计和分解，这边新建Homography类，用于处理单应矩阵估计和分解。具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bool Homography::computeSE3fromMatches()</span><br><span class="line">&#123;</span><br><span class="line">calcFromMatches();//计算单应</span><br><span class="line">bool res = decompose();// 将单应矩阵进行分解</span><br><span class="line">if (!res)</span><br><span class="line">return false;</span><br><span class="line">computeMatchesInliers();// 计算匹配的内点数</span><br><span class="line">findBestDecomposition();// 找出最好的分解</span><br><span class="line">T_c2_from_c1 = decompositions[0].T;</span><br><span class="line">return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>首先先计算单应矩阵，目前采用OpenCV的函数cv::findHomography来进行计算，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">void Homography::calcFromMatches()</span><br><span class="line">&#123;</span><br><span class="line">std::vector&lt;cv::Point2f&gt; src_pts(fts_c1_.size()), dst_pts(fts_c1_.size());</span><br><span class="line">for (size_t i = 0; i &lt; fts_c1_.size(); ++i)</span><br><span class="line">&#123;</span><br><span class="line">src_pts[i] = cv::Point2f(fts_c1_[i][0], fts_c1_[i][1]);</span><br><span class="line">dst_pts[i] = cv::Point2f(fts_c2_[i][0], fts_c2_[i][1]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cv::Mat cvH = cv::findHomography(src_pts, dst_pts, CV_RANSAC, 2. / focal_length_);</span><br><span class="line">H_c2_from_c1_(0, 0) = cvH.at&lt;double&gt;(0, 0);</span><br><span class="line">H_c2_from_c1_(0, 1) = cvH.at&lt;double&gt;(0, 1);</span><br><span class="line">H_c2_from_c1_(0, 2) = cvH.at&lt;double&gt;(0, 2);</span><br><span class="line">H_c2_from_c1_(1, 0) = cvH.at&lt;double&gt;(1, 0);</span><br><span class="line">H_c2_from_c1_(1, 1) = cvH.at&lt;double&gt;(1, 1);</span><br><span class="line">H_c2_from_c1_(1, 2) = cvH.at&lt;double&gt;(1, 2);</span><br><span class="line">H_c2_from_c1_(2, 0) = cvH.at&lt;double&gt;(2, 0);</span><br><span class="line">H_c2_from_c1_(2, 1) = cvH.at&lt;double&gt;(2, 1);</span><br><span class="line">H_c2_from_c1_(2, 2) = cvH.at&lt;double&gt;(2, 2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>这边注意了，对于cv::findHomography的参数ransacReprojThreshold，这边单位不是像素，有1/focal_length的scale</strong>，更详细的使用参考：</p>
<p><img src="http://7xl6tk.com1.z0.glb.clouddn.com/findHomography.png" alt></p>
<p>下一步进行单应矩阵分解，具体过程可以参考[1]，具体代码实现参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">bool Homography::decompose()</span><br><span class="line">&#123;</span><br><span class="line">decomp_size_ = 0;</span><br><span class="line">JacobiSVD&lt;MatrixXd&gt; svd(H_c2_from_c1_, ComputeThinU | ComputeThinV);</span><br><span class="line">Vector3d singular_values = svd.singularValues();</span><br><span class="line">// 获得3个特征量</span><br><span class="line">double d1 = fabs(singular_values[0]); </span><br><span class="line">double d2 = fabs(singular_values[1]); </span><br><span class="line">double d3 = fabs(singular_values[2]);</span><br><span class="line"></span><br><span class="line">Matrix3d U = svd.matrixU();</span><br><span class="line">Matrix3d V = svd.matrixV();                    // VT^T</span><br><span class="line"></span><br><span class="line">double s = U.determinant() * V.determinant();</span><br><span class="line"></span><br><span class="line">double dPrime_PM = d2;</span><br><span class="line"></span><br><span class="line">int nCase;</span><br><span class="line">if (d1 != d2 &amp;&amp; d2 != d3)</span><br><span class="line">nCase = 1;</span><br><span class="line">else if (d1 == d2 &amp;&amp; d2 == d3)</span><br><span class="line">nCase = 3;</span><br><span class="line">else</span><br><span class="line">nCase = 2;</span><br><span class="line">if (nCase != 1)</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;FATAL Homography Initialization: This motion case is not implemented or is degenerate. Try again. &quot;);</span><br><span class="line">return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double x1_PM;</span><br><span class="line">double x2;</span><br><span class="line">double x3_PM;</span><br><span class="line">// 在情况1下(d1 != d3)</span><br><span class="line">&#123; // Eq. 12</span><br><span class="line">x1_PM = sqrt((d1*d1 - d2*d2) / (d1*d1 - d3*d3));</span><br><span class="line">x2 = 0;</span><br><span class="line">x3_PM = sqrt((d2*d2 - d3*d3) / (d1*d1 - d3*d3));</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">double e1[4] = &#123; 1.0, -1.0, 1.0, -1.0 &#125;;</span><br><span class="line">double e3[4] = &#123; 1.0, 1.0, -1.0, -1.0 &#125;;</span><br><span class="line"></span><br><span class="line">Vector3d np;</span><br><span class="line">HomographyDecomposition decomp;</span><br><span class="line"></span><br><span class="line">// Case 1, d&apos; &gt; 0:</span><br><span class="line">decomp.d = s * dPrime_PM;</span><br><span class="line">for (size_t signs = 0; signs &lt; 4; signs++)</span><br><span class="line">&#123;</span><br><span class="line">// Eq 13</span><br><span class="line">decomp.R = Matrix3d::Identity();</span><br><span class="line">double dSinTheta = (d1 - d3) * x1_PM * x3_PM * e1[signs] * e3[signs] / d2;</span><br><span class="line">double dCosTheta = (d1 * x3_PM * x3_PM + d3 * x1_PM * x1_PM) / d2;</span><br><span class="line">decomp.R(0, 0) = dCosTheta;</span><br><span class="line">decomp.R(0, 2) = -dSinTheta;</span><br><span class="line">decomp.R(2, 0) = dSinTheta;</span><br><span class="line">decomp.R(2, 2) = dCosTheta;</span><br><span class="line">// Eq 14</span><br><span class="line">decomp.t[0] = (d1 - d3) * x1_PM * e1[signs];</span><br><span class="line">decomp.t[1] = 0.0;</span><br><span class="line">decomp.t[2] = (d1 - d3) * -x3_PM * e3[signs];</span><br><span class="line">np[0] = x1_PM * e1[signs];</span><br><span class="line">np[1] = x2;</span><br><span class="line">np[2] = x3_PM * e3[signs];</span><br><span class="line">decomp.n = V * np;</span><br><span class="line">decompositions_[decomp_size_++] = decomp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Case 1, d&apos; &lt; 0:</span><br><span class="line">decomp.d = s * -dPrime_PM;</span><br><span class="line">for (size_t signs = 0; signs &lt; 4; signs++)</span><br><span class="line">&#123;</span><br><span class="line">// Eq 15</span><br><span class="line">decomp.R = -1 * Matrix3d::Identity();</span><br><span class="line">double dSinPhi = (d1 + d3) * x1_PM * x3_PM * e1[signs] * e3[signs] / d2;</span><br><span class="line">double dCosPhi = (d3 * x1_PM * x1_PM - d1 * x3_PM * x3_PM) / d2;</span><br><span class="line">decomp.R(0, 0) = dCosPhi;</span><br><span class="line">decomp.R(0, 2) = dSinPhi;</span><br><span class="line">decomp.R(2, 0) = dSinPhi;</span><br><span class="line">decomp.R(2, 2) = -dCosPhi;</span><br><span class="line"></span><br><span class="line">// Eq 16</span><br><span class="line">decomp.t[0] = (d1 + d3) * x1_PM * e1[signs];</span><br><span class="line">decomp.t[1] = 0.0;</span><br><span class="line">decomp.t[2] = (d1 + d3) * x3_PM * e3[signs];</span><br><span class="line"></span><br><span class="line">np[0] = x1_PM * e1[signs];</span><br><span class="line">np[1] = x2;</span><br><span class="line">np[2] = x3_PM * e3[signs];</span><br><span class="line">decomp.n = V * np;</span><br><span class="line"></span><br><span class="line">decompositions_[decomp_size_++] = decomp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 保存分解之后的旋转和平移，Eq 8</span><br><span class="line">for (unsigned int i = 0; i &lt; decomp_size_; i++)</span><br><span class="line">&#123;</span><br><span class="line">Matrix3d R = s * U * decompositions_[i].R * V.transpose();</span><br><span class="line">Vector3d t = U * decompositions_[i].t;</span><br><span class="line">decompositions_[i].T = Sophus::SE3(R, t);</span><br><span class="line">&#125;</span><br><span class="line">return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>通过svd分解，根据特征值条件，构建了8组理论解。下一步就是找到最好的分解，在此之前先找到内点数（也就是图像中符合计算出的单应矩阵的特征点），通过内点来进行验证。具体给内点打上标识，过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">size_t Homography::computeMatchesInliers()</span><br><span class="line">&#123;</span><br><span class="line">inliers_.clear(); inliers_.resize(fts_c1_.size());</span><br><span class="line">size_t n_inliers = 0;</span><br><span class="line">for (size_t i = 0; i &lt; fts_c1_.size(); i++)</span><br><span class="line">&#123;</span><br><span class="line">Vector2d projected = project2d(H_c2_from_c1_ * unproject2d(fts_c1_[i]));</span><br><span class="line">Vector2d e = fts_c2_[i] - projected;</span><br><span class="line">double e_px = focal_length_ * e.norm();//化为像素距离</span><br><span class="line">inliers_[i] = (e_px &lt; thresh_);//也就是残差在阈值范围内</span><br><span class="line">n_inliers += inliers_[i];</span><br><span class="line">&#125;</span><br><span class="line">return n_inliers;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面根据两个判断，1、特征点在摄像机的前面，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for (size_t i = 0; i &lt; decomp_size_; i++)</span><br><span class="line">&#123;</span><br><span class="line">HomographyDecomposition &amp;decom = decompositions_[i];</span><br><span class="line">int positive = 0;</span><br><span class="line">for (size_t m = 0; m &lt; fts_c1_.size(); m++)</span><br><span class="line">&#123;</span><br><span class="line">if (!inliers_[m])</span><br><span class="line">continue;</span><br><span class="line">const Vector2d&amp; v2 = fts_c1_[m];</span><br><span class="line">double visibility_test = (H_c2_from_c1_(2, 0) * v2[0] + H_c2_from_c1_(2, 1) * v2[1] + H_c2_from_c1_(2, 2)) / decom.d;</span><br><span class="line">if (visibility_test &gt; 0.0)</span><br><span class="line">positive++;</span><br><span class="line">&#125;</span><br><span class="line">decom.score = -positive;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>2、通过参考平面的法向量与摄像机光线方向的夹角小于90度来进一步过滤。具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for (size_t i = 0; i &lt; decomp_size_; i++)</span><br><span class="line">&#123;</span><br><span class="line">HomographyDecomposition &amp;decom = decompositions_[i];</span><br><span class="line">int positive = 0;</span><br><span class="line">for (size_t m = 0; m &lt; fts_c1_.size(); m++)</span><br><span class="line">&#123;</span><br><span class="line">if (!inliers_[m])</span><br><span class="line">continue;</span><br><span class="line">Vector3d v3 = unproject2d(fts_c1_[m]);</span><br><span class="line">double visibility_test = v3.dot(decom.n) / decom.d;</span><br><span class="line">if (visibility_test &gt; 0.0)</span><br><span class="line">positive++;</span><br><span class="line">&#125;;</span><br><span class="line">decom.score = -positive;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>提示：点乘为负，则说明夹角大于90度。&lt;/br&gt;<br>这样就剩下了2组可能的姿态，最后通过对上述计算的score计算比如，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">double ratio = (double)decompositions_[1].score / (double)decompositions_[0].score;</span><br></pre></td></tr></table></figure></p>
<p>如果ratio的值小于0.9，则确定了分解，如果大于0.9，则通过计算的R,tR,t计算本质矩阵后计算sampsonus error来进行判断。<strong>不过这边计算sampsonus error不是很明白为什么这么计算，有明白的，还望不吝赐教</strong>，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">double sampsonusError(const Vector2d &amp;v2Dash, const Matrix3d&amp; essential, const Vector2d&amp; v2)</span><br><span class="line">&#123;</span><br><span class="line">Vector3d v3Dash = unproject2d(v2Dash);</span><br><span class="line">Vector3d v3 = unproject2d(v2);</span><br><span class="line"></span><br><span class="line">double error = v3Dash.transpose() * essential * v3;</span><br><span class="line"></span><br><span class="line">Vector3d fv3 = essential * v3;</span><br><span class="line">Vector3d fTv3Dash = essential.transpose() * v3Dash;</span><br><span class="line"></span><br><span class="line">Vector2d fv3Slice = fv3.head&lt;2&gt;();</span><br><span class="line">Vector2d fTv3DashSlice = fTv3Dash.head&lt;2&gt;();</span><br><span class="line"></span><br><span class="line">return (error * error / (fv3Slice.dot(fv3Slice) + fTv3DashSlice.dot(fTv3DashSlice)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>分解结束之后计算内点和三角定点计算3D点，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">void Initialization::computeHomography(</span><br><span class="line">const std::vector&lt;Vector3d&gt;&amp; f_ref,</span><br><span class="line">const std::vector&lt;Vector3d&gt;&amp; f_cur,</span><br><span class="line">double focal_length,</span><br><span class="line">double reprojection_threshold,</span><br><span class="line">std::vector&lt;int&gt;&amp; inliers,</span><br><span class="line">std::vector&lt;Vector3d&gt;&amp; xyz_in_cur,</span><br><span class="line">SE3&amp; T_cur_from_ref)</span><br><span class="line">&#123;</span><br><span class="line">std::vector&lt;Vector2d, aligned_allocator&lt;Vector2d&gt; &gt; uv_ref(f_ref.size());</span><br><span class="line">std::vector&lt;Vector2d, aligned_allocator&lt;Vector2d&gt; &gt; uv_cur(f_cur.size());</span><br><span class="line">for (size_t i = 0, i_max = f_ref.size(); i &lt; i_max; ++i)</span><br><span class="line">&#123;</span><br><span class="line">uv_ref[i] = project2d(f_ref[i]);</span><br><span class="line">uv_cur[i] = project2d(f_cur[i]);</span><br><span class="line">&#125;</span><br><span class="line">Homography Homography(uv_ref, uv_cur, focal_length, reprojection_threshold);</span><br><span class="line">Homography.computeSE3fromMatches();</span><br><span class="line">std::vector&lt;int&gt; outliers;</span><br><span class="line">computeInliers(f_cur, f_ref,</span><br><span class="line">Homography.T_c2_from_c1_.rotation_matrix(), Homography.T_c2_from_c1_.translation(),</span><br><span class="line">reprojection_threshold, focal_length,</span><br><span class="line">xyz_in_cur, inliers, outliers);</span><br><span class="line">T_cur_from_ref = Homography.T_c2_from_c1_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这边给出一个提示，因为要保证16字节对齐，对于Vector2d之类的容器形式要写成 <code>std::vector&lt;Vector2d, aligned_allocator&lt;Vector2d&gt;&gt;</code>，对于Vector3f 或 MatrixXd之类的，则不考虑，具体可以参考&lt;/br&gt;<br><a href="http://eigen.tuxfamily.org/dox/group__TopicStlContainers.html" target="_blank" rel="noopener">http://eigen.tuxfamily.org/dox/group__TopicStlContainers.html</a>&lt;/br&gt;<br>对于函数computeInliers首先先进行三角定位，确定两个关联特征对应的3D点，根据3D进行反投影，通过阈值对反投影的误差的关系确定内外点，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">double computeInliers(const std::vector&lt;Vector3d&gt;&amp; features1, // c1</span><br><span class="line">const std::vector&lt;Vector3d&gt;&amp; features2, // c2</span><br><span class="line">const Matrix3d&amp; R,                 // R_c1_c2</span><br><span class="line">const Vector3d&amp; t,                 // c1_t</span><br><span class="line">const double reproj_thresh,</span><br><span class="line">double focal_length,</span><br><span class="line">std::vector&lt;Vector3d&gt;&amp; xyz_vec,         // in frame c1</span><br><span class="line">std::vector&lt;int&gt;&amp; inliers,</span><br><span class="line">std::vector&lt;int&gt;&amp; outliers)</span><br><span class="line">&#123;</span><br><span class="line">inliers.clear(); inliers.reserve(features1.size());</span><br><span class="line">outliers.clear(); outliers.reserve(features1.size());</span><br><span class="line">xyz_vec.clear(); xyz_vec.reserve(features1.size());</span><br><span class="line">double tot_error = 0;</span><br><span class="line">//三角化所有特征，然后计算投影误差和内点</span><br><span class="line">for (size_t j = 0; j&lt;features1.size(); ++j)</span><br><span class="line">&#123;</span><br><span class="line">xyz_vec.push_back(triangulateFeatureNonLin(R, t, features1[j], features2[j]));</span><br><span class="line">double e1 = reprojError(features1[j], xyz_vec.back(), focal_length);</span><br><span class="line">double e2 = reprojError(features2[j], R.transpose()*(xyz_vec.back() - t), focal_length);</span><br><span class="line">if (e1 &gt; reproj_thresh || e2 &gt; reproj_thresh)</span><br><span class="line">outliers.push_back(j);</span><br><span class="line">else</span><br><span class="line">&#123;</span><br><span class="line">inliers.push_back(j);</span><br><span class="line">tot_error += e1 + e2;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return tot_error;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>但是这边三角定位确定3D点还是有点不太明白</strong>，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Vector3d triangulateFeatureNonLin(const Matrix3d&amp; R, const Vector3d&amp; t,</span><br><span class="line">const Vector3d&amp; feature1, const Vector3d&amp; feature2)</span><br><span class="line">&#123;</span><br><span class="line">Vector3d f2 = R * feature2;</span><br><span class="line">Vector2d b;</span><br><span class="line">b[0] = t.dot(feature1);</span><br><span class="line">b[1] = t.dot(f2);</span><br><span class="line">Matrix2d A;</span><br><span class="line">A(0, 0) = feature1.dot(feature1);</span><br><span class="line">A(1, 0) = feature1.dot(f2);</span><br><span class="line">A(0, 1) = -A(1, 0);</span><br><span class="line">A(1, 1) = -f2.dot(f2);</span><br><span class="line">Vector2d lambda = A.inverse() * b;</span><br><span class="line">Vector3d xm = lambda[0] * feature1;</span><br><span class="line">Vector3d xn = t + lambda[1] * f2;</span><br><span class="line">return (xm + xn) / 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>到这里单应矩阵的估计、分解就结束了，结束之后要对计算得到的内点数添加阈值控制，要确保内点数大于40.&lt;/br&gt;<br>下一步就是尺度估计，离相机的距离不同，则图像的尺度不一样，采用的方法是计算上面计算的所有3D点所有深度的中值scene_depth_median，则此时尺度为<strong>scale = 1.0 / scene_depth_median;</strong>&lt;/br&gt;<br>    注意：1. 对于单目视觉里程计是不知道尺度信息的，也就是在第一帧的时候，我们假设了特征对应的3D点的深度为1。</p>
<ol>
<li>也就是目前是通过计算下一帧所有特征对应的3D点深度的中值作为尺度计算值，这也就限制了算法的使用场景，定位相机应尽可能的对着一个平面，所以朝地是一个很好的选择</li>
</ol>
<p>接下来计算当前帧的相机外参，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 计算相对变换SE3</span><br><span class="line">frame_cur-&gt;T_f_w_ = T_cur_from_ref_ * frame_ref_-&gt;T_f_w_;</span><br><span class="line"></span><br><span class="line">// 对位移变换添加尺度</span><br><span class="line">frame_cur-&gt;T_f_w_.translation() = -frame_cur-&gt;T_f_w_.rotation_matrix()*(frame_ref_-&gt;pos() + scale*(frame_cur-&gt;pos() - frame_ref_-&gt;pos()));</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>这边注意要对位移变换添加尺度变换，原因是我们实际是假设深度为1的情况下进行计算，而实际深度是不是1，要转变到实际深度情况下的值。另外pos=(−R^(−1))*t&lt;/br&gt;<br>最后对每个内点创建3D点，设置特征，添加到这两帧中，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">SE3 T_world_cur = frame_cur-&gt;T_f_w_.inverse();</span><br><span class="line">for (std::vector&lt;int&gt;::iterator it = inliers_.begin(); it != inliers_.end(); ++it)</span><br><span class="line">&#123;</span><br><span class="line">Vector2d px_cur(px_cur_[*it].x, px_cur_[*it].y);</span><br><span class="line">Vector2d px_ref(px_ref_[*it].x, px_ref_[*it].y);</span><br><span class="line">if (frame_ref_-&gt;cam_-&gt;isInFrame(px_cur.cast&lt;int&gt;(), 10) &amp;&amp; frame_ref_-&gt;cam_-&gt;isInFrame(px_ref.cast&lt;int&gt;(), 10) &amp;&amp; xyz_in_cur_[*it].z() &gt; 0)</span><br><span class="line">&#123;</span><br><span class="line">Vector3d pos = T_world_cur * (xyz_in_cur_[*it] * scale);// 将相机下的点坐标转世界坐标</span><br><span class="line">Point3D *new_point = new Point3D(pos);</span><br><span class="line"></span><br><span class="line">Feature* ftr_cur = new Feature(frame_cur.get(), new_point, px_cur, f_cur_[*it], 0);</span><br><span class="line">frame_cur-&gt;addFeature(ftr_cur);</span><br><span class="line">// 将同一个点对应的特征保存起来，这样点删除了，对应的特征都可以删除</span><br><span class="line">new_point-&gt;addFrameRef(ftr_cur);</span><br><span class="line"></span><br><span class="line">Feature* ftr_ref = new Feature(frame_ref_.get(), new_point, px_ref, f_ref_[*it], 0);</span><br><span class="line">frame_ref_-&gt;addFeature(ftr_ref);</span><br><span class="line">new_point-&gt;addFrameRef(ftr_ref);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>到这里整个初始位置的确定就结束了，主要思想就是通过光流跟踪获得对应特征点对，通过对应特征点对估计单应矩阵，将单应矩阵进行分解或者相机外参数据，这个里面主要要注意的是检测到特征的点数，跟踪的特征点数，计算单应矩阵特征的内点数进行阈值限定，以及scale的估计。&lt;/br&gt;<br>最后写一个简单的测试程序对上述过程进行简单测试，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">CmdLine cmd;</span><br><span class="line">std::string first_frame_name;</span><br><span class="line">std::string second_frame_name;</span><br><span class="line"></span><br><span class="line">cmd.add(make_option(&apos;f&apos;, first_frame_name, &quot;firstname&quot;));</span><br><span class="line">cmd.add(make_option(&apos;s&apos;, second_frame_name, &quot;secondname&quot;));</span><br><span class="line">try &#123;</span><br><span class="line">if (argc == 1) throw std::string(&quot;Invalid command line parameter.&quot;);</span><br><span class="line">cmd.process(argc, argv);</span><br><span class="line">&#125;</span><br><span class="line">catch (const std::string&amp; s) &#123;</span><br><span class="line">std::cerr &lt;&lt; &quot;Feature detector \nUsage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot;\n&quot;</span><br><span class="line">&lt;&lt; &quot;[-f|--firstname name]\n&quot;</span><br><span class="line">&lt;&lt; &quot;[-s|--secondname name]\n&quot;</span><br><span class="line">&lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">std::cerr &lt;&lt; s &lt;&lt; std::endl;</span><br><span class="line">return EXIT_FAILURE;</span><br><span class="line">&#125;</span><br><span class="line">cv::Mat first_img(cv::imread(first_frame_name, 0));</span><br><span class="line">cv::Mat second_img(cv::imread(second_frame_name, 0));</span><br><span class="line">assert(first_img.type() == CV_8UC1 &amp;&amp; !first_img.empty());</span><br><span class="line">assert(second_img.type() == CV_8UC1 &amp;&amp; !second_img.empty());</span><br><span class="line"></span><br><span class="line">AbstractCamera* cam = new PinholeCamera(752, 480, 315.5, 315.5, 376.0, 240.0);</span><br><span class="line"></span><br><span class="line">FramePtr fisrt_frame(new Frame(cam, first_img, 0.0));</span><br><span class="line">FramePtr second_frame(new Frame(cam, second_img, 1.0));</span><br><span class="line"></span><br><span class="line">Initialization init;</span><br><span class="line">init.addFirstFrame(fisrt_frame);</span><br><span class="line">init.addSecondFrame(second_frame);</span><br><span class="line">std::cout &lt;&lt; second_frame-&gt;T_f_w_ &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>结果如下：</p>
<p><img src="http://7xl6tk.com1.z0.glb.clouddn.com/initial_position.png" alt></p>
<h2 id="下一步计划"><a href="#下一步计划" class="headerlink" title="下一步计划"></a>下一步计划</h2><p>上面完成了初始位置的确定，下一步就开始处理连续帧，进行motion estimation和mapping。&lt;/br&gt;<br>[1] Faugeras O D, Lustman F. Motion and structure from motion in a piecewise planar environment[J]. International Journal of Pattern Recognition and Artificial Intelligence, 1988, 2(03): 485-508.</p>
<p>转载自冯兵的博客，<a href="http://fengbing.net/2015/08/15/%E4%B8%80%E6%AD%A5%E6%AD%A5%E5%AE%9E%E7%8E%B0%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A13%E2%80%94%E2%80%94%E5%88%9D%E5%A7%8B%E4%BD%8D%E7%BD%AE%E7%A1%AE%E5%AE%9A/" target="_blank" rel="noopener">原文链接</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/09/18/一步步完善视觉里程计3——初始位置确定/" data-id="cjtl7u74y000rx3xyoujyutsr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/09/18/一步步完善视觉里程计4——运动估计image-align/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          一步步完善视觉里程计4——运动估计image align
        
      </div>
    </a>
  
  
    <a href="/2017/09/17/一步步完善视觉里程计2——FAST特征检测/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">一步步完善视觉里程计2——FAST特征检测</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/robot/">robot</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/">Java</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/Android/">Android</a></li></ul></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROS/">ROS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SAE/">SAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/directions/">directions</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/donation/">donation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/goal/">goal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello/">hello</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/helloworld/">helloworld</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/robot/">robot</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ROS/" style="font-size: 10px;">ROS</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/directions/" style="font-size: 10px;">directions</a> <a href="/tags/donation/" style="font-size: 10px;">donation</a> <a href="/tags/goal/" style="font-size: 20px;">goal</a> <a href="/tags/hello/" style="font-size: 10px;">hello</a> <a href="/tags/helloworld/" style="font-size: 10px;">helloworld</a> <a href="/tags/robot/" style="font-size: 10px;">robot</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/21/角度光流/">角度光流</a>
          </li>
        
          <li>
            <a href="/2019/03/20/Nature和Science关于机器人方面的文章总结/">Nature和Science关于机器人方面的总结</a>
          </li>
        
          <li>
            <a href="/2019/03/12/警犬项目经验总结/">警犬项目经验总结</a>
          </li>
        
          <li>
            <a href="/2019/03/12/[转]ROS机器人编程：原理与应用/">『转』ROS机器人编程：原理与应用</a>
          </li>
        
          <li>
            <a href="/2018/05/07/SVO详解/">SVO详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Hhu_GFBlab<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>