<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>DSO详解 | Blackant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="DSO（Direct Sparse Odometry），是慕尼黑工业大学（Technical University of Munich, TUM）计算机视觉实验室的雅各布.恩格尔（Jakob Engel）博士，于2016年发布的一个视觉里程计方法（期刊论文见[1]，实验室主页见Computer Vision Group）。在SLAM领域，DSO属于稀疏直接法，据论文称能达到传统特征点法的五倍速度（">
<meta property="og:type" content="article">
<meta property="og:title" content="DSO详解">
<meta property="og:url" content="http://yoursite.com/2017/09/19/DSO详解/index.html">
<meta property="og:site_name" content="Blackant">
<meta property="og:description" content="DSO（Direct Sparse Odometry），是慕尼黑工业大学（Technical University of Munich, TUM）计算机视觉实验室的雅各布.恩格尔（Jakob Engel）博士，于2016年发布的一个视觉里程计方法（期刊论文见[1]，实验室主页见Computer Vision Group）。在SLAM领域，DSO属于稀疏直接法，据论文称能达到传统特征点法的五倍速度（">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/img/SLAM.png">
<meta property="og:image" content="http://yoursite.com/img/che.png">
<meta property="og:image" content="http://yoursite.com/img/liu.png">
<meta property="og:image" content="http://yoursite.com/img/kuang.png">
<meta property="og:image" content="http://yoursite.com/img/cheng.png">
<meta property="og:image" content="http://yoursite.com/img/xi.png">
<meta property="og:image" content="http://yoursite.com/img/hh.png">
<meta property="og:image" content="http://yoursite.com/img/h.png">
<meta property="og:image" content="http://yoursite.com/img/j.png">
<meta property="og:image" content="http://yoursite.com/img/a.png">
<meta property="og:image" content="http://yoursite.com/img/b.png">
<meta property="og:image" content="http://yoursite.com/img/r.png">
<meta property="og:image" content="http://yoursite.com/img/c.png">
<meta property="og:image" content="http://yoursite.com/img/d.png">
<meta property="og:image" content="http://yoursite.com/img/rho.png">
<meta property="og:image" content="http://yoursite.com/img/w.png">
<meta property="og:image" content="http://yoursite.com/img/q.png">
<meta property="og:image" content="http://yoursite.com/img/e.png">
<meta property="og:image" content="http://yoursite.com/img/f.png">
<meta property="og:image" content="http://yoursite.com/img/y.png">
<meta property="og:image" content="http://yoursite.com/img/z.png">
<meta property="og:image" content="http://yoursite.com/img/u.png">
<meta property="og:image" content="http://yoursite.com/img/m.png">
<meta property="og:image" content="http://yoursite.com/img/n.png">
<meta property="og:image" content="http://yoursite.com/img/v.png">
<meta property="og:image" content="http://yoursite.com/img/2222.png">
<meta property="og:image" content="http://yoursite.com/img/i.png">
<meta property="og:image" content="http://yoursite.com/img/x.png">
<meta property="og:image" content="http://yoursite.com/img/1.png">
<meta property="og:image" content="http://yoursite.com/img/g.png">
<meta property="og:image" content="http://yoursite.com/img/p.png">
<meta property="og:image" content="http://yoursite.com/img/3.png">
<meta property="og:image" content="http://yoursite.com/img/4.png">
<meta property="og:image" content="http://yoursite.com/img/5.png">
<meta property="og:updated_time" content="2019-02-21T08:49:15.529Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DSO详解">
<meta name="twitter:description" content="DSO（Direct Sparse Odometry），是慕尼黑工业大学（Technical University of Munich, TUM）计算机视觉实验室的雅各布.恩格尔（Jakob Engel）博士，于2016年发布的一个视觉里程计方法（期刊论文见[1]，实验室主页见Computer Vision Group）。在SLAM领域，DSO属于稀疏直接法，据论文称能达到传统特征点法的五倍速度（">
<meta name="twitter:image" content="http://yoursite.com/img/SLAM.png">
  
    <link rel="alternate" href="/atom.xml" title="Blackant" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Blackant</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-DSO详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/19/DSO详解/" class="article-date">
  <time datetime="2017-09-19T02:31:14.000Z" itemprop="datePublished">2017-09-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      DSO详解
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>DSO（Direct Sparse Odometry），是慕尼黑工业大学（Technical University of Munich, TUM）计算机视觉实验室的雅各布.恩格尔（Jakob Engel）博士，于2016年发布的一个视觉里程计方法（期刊论文见[1]，实验室主页见<a href="https://vision.in.tum.de/" target="_blank" rel="noopener">Computer Vision Group</a>）。在SLAM领域，DSO属于稀疏直接法，据论文称能达到传统特征点法的五倍速度（需要降低图像分辨率），并保持同等或更高精度，代码见：<a href="https://github.com/JakobEngel/dso" target="_blank" rel="noopener">JakobEngel/dso</a>。然而，由于某些历史和个人的原因，DSO的代码清晰度和可读性，明显弱于其他SLAM方案如ORB、SVO、okvis等，使得研究人员很难以它为基础，展开后续的研究工作。因此，本文希望从理论和实现层面解读DSO，尝试为其他对DSO感兴趣的研究人员提供一些有益的思路和观点。<a id="more"></a></p>
<pre><code>朋友，过去的时代对于我们
好比打着七重封印的密籍
你称为时代精神的那东西
它终归不过是过去的时代
反映在学究先生的精神里。
    ——《浮士德》

他掘了坑，又挖深了，竟掉在自己所挖的阱裡。
——《圣经 诗篇 7.15》
</code></pre><p>注：</p>
<ul>
<li>为了读懂本文，我们假定读者已具有视觉SLAM的基本知识，否则，请先阅读相关材料。另外，如果读过DSO论文或代码，可能对本文有更好的理解。</li>
<li>由于知乎平台分辨率限制，插图可能不够清晰。如果能图像质量有更高要求，请联系作者：gao.xiang.thu@gmail.com.</li>
<li>由于本文较长，我会花几次时间进行更新，应读者要求先发布草稿版。</li>
</ul>
<p>以下是本文的提纲：</p>
<ol>
<li>概述</li>
<li>流程框架</li>
<li>滑动窗口</li>
<li>光度标定</li>
<li>评述</li>
<li>资料与参考文献</li>
</ol>
<p><img src="/img/SLAM.png" alt><br><img src="/img/che.png" alt></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>DSO属于稀疏直接法的视觉里程计。它不是完整的SLAM，因为它不包含回环检测、地图复用的功能。因此，它不可避免地会出现累计误差，尽管很小，但不能消除。DSO目前开源了单目实现，双目DSO的论文已被ICCV接收，但目前未知是否开源。</p>
<p>DSO是少数使用纯直接法（Fully direct）计算视觉里程计的系统之一。相比之下，SVO[2]属于半直接法，仅在前端的Sparse model-based Image Alignment部分使用了直接法，之后的位姿估计、bundle adjustment，则仍旧使用传统的最小化重投影误差的方式。而ORB-SLAM2[3]，则属于纯特征法，计算结果完全依赖特征匹配。从方法上来说，DSO是新颖、独树一帜的。</p>
<p>直接法相比于特征点法，有两个非常不同的地方：</p>
<ul>
<li>特征点法通过最小化重投影误差来计算相机位姿与地图点的位置，而直接法则最小化光度误差（photometric error）。所谓光度误差是说，最小化的目标函数，通常由图像之间的误差来决定，而非重投影之后的几何误差。</li>
<li>直接法将数据关联（data association）与位姿估计（pose estimation）放在了一个统一的非线性优化问题中，而特征点法则分步求解，即，先通过匹配特征点求出数据之间关联，再根据关联来估计位姿。这两步通常是独立的，在第二步中，可以通过重投影误差来判断数据关联中的外点，也可以用于修正匹配结果（例如[4]中提到的类EM的方法）。</li>
</ul>
<p><img src="/img/liu.png" alt></p>
<p>由于这个原因，DSO会一直求解一个比较复杂的优化问题，我们很难将它划分为像特征点法那样一步一步的过程。DSO甚至没有“匹配点”这个概念。每一个三维点，从某个主导帧（host frame）出发，乘上深度值之后投影至另一个目标帧（target frame），从而建立一个投影残差（residual）。只要残差在合理范围内，就可以认为这些点是由同一个点投影的。从数据关联角度看，在这个过程中并没有a1-b1, a2-b2这样的关系，也可能存在a1-b1, a2-b1, a3-b1这样的情况。但是DSO并不在意这些，只要残差不大，我们就看成是同一个点。这是很重要的一点。在特征点法中，我们可以找到一个地图点分别在哪些帧中被看到，乃至找到各帧中的图像描述子是什么；但在DSO中，我们会尝试把每个点投影到所有帧中，计算它在各帧中的残差，而并不在意点和点之间的一一对应关系。</p>
<p>从后端来看，DSO使用一个由若干个关键帧组成的滑动窗口作为它的后端。这个窗口在整个VO过程中一直存在，并有一套方法来管理新数据的加入以及老数据的去除。具体来说，这个窗口通常保持5到7个关键帧。前端追踪部分，会通过一定的条件，来判断新来的帧是否可作为新的关键帧插入后端。同时，如果后端发现关键帧数已经大于窗口大小，也会通过特定的方法，选择其中一个帧进行去除。请注意被去除的帧并不一定是时间线上最旧的那个帧，而是会有一些复杂条件的。</p>
<p>后端除了维护这个窗口中的关键帧与地图点外，还会维护与优化相关的结构。特别地，这里指Gauss-Newton或Levenburg-Marquardt方法中的Hessian矩阵和b向量（仅先验部分）。当我们增加新的关键帧时，就必须扩展H和b的维度；反之，如果需要去掉某个关键帧（以及它携带的地图点）时，也需要降低H和b的维度。这个过程还需要将被删掉帧和点的信息，转移到窗口内剩余帧当中，这一步被称为边缘化（Marginalization）。</p>
<p>由于直接法需要比较图像信息，其结果容易受光照干扰。于是，DSO提出了光度标定，认为对相机的曝光时间、暗角、伽马响应等参数进行标定后，能够让直接法更加鲁棒。对于未进行光度标定的相机，DSO也会在优化中动态估计光度参数（具体来说，是一个仿射变化的参数，记作a和b）。这个过程建模了相机的成像过程，因此对于由相机曝光不同引起的图像明暗变化，会有更好的表现。但是，如果由于环境光源发生变化，光度标定也是无能为力的。</p>
<p>本文第2节介绍DSO基本框架和流程。第3节介绍滑动窗口内的最小二乘问题、雅可比、边缘化。第4节介绍光度标定。第5节会给出我个人对DSO的一些评述。最后列出参考文献。DSO相关的实验、比较结果，请参见作者原始论文，在此不作叙述。</p>
<h2 id="框架流程"><a href="#框架流程" class="headerlink" title="框架流程"></a>框架流程</h2><h3 id="代码框架与数据表示"><a href="#代码框架与数据表示" class="headerlink" title="代码框架与数据表示"></a>代码框架与数据表示</h3><p>现在我们来看DSO的大体框架。我去除了一些不重要的类和结构，方便读者阅读。</p>
<p><img src="/img/kuang.png" alt></p>
<p>DSO整体代码由四个部分组成：系统与各算法集成于src/FullSystem，后端优化位于src/OptimizationBackend，这二者组成了DSO大部分核心内容。src/utils和src/IOWrapper为一些去畸变、数据集读写和可视化UI代码。先来看核心部分的FullSystem和OptimizationBackend。</p>
<p>如上图上半部分所示，在FullSystem里，DSO致力于维护一个滑动窗口内部的关键帧序列。每个帧的数据存储于FrameHessian结构体中，FrameHessian即是一个带着状态变量与Hessian信息的帧。然后，每个帧亦携带一些地图点的信息，包括：</p>
<ul>
<li>pointHessians是所有活跃点的信息。所谓活跃点，是指它们在相机的视野中，其残差项仍在参与优化部分的计算；</li>
<li>pointHessiansMarginalized是已经边缘化的地图点。</li>
<li>pointHessiansOut是被判为外点（outlier）的地图点。</li>
<li>以及immaturePoints为未成熟地图点的信息。</li>
</ul>
<p>在单目SLAM中，所有地图点在一开始被观测到时，都只有一个2D的像素坐标，其深度是未知的。这种点在DSO中称为未成熟的地图点：Immature Points。随着相机的运动，DSO会在每张图像上追踪这些未成熟的地图点，这个过程称为trace——实际上是一个沿着极线搜索的过程，十分类似于svo的depth filter。Trace的过程会确定每个Immature Point的逆深度和它的变化范围。如果Immature Point的深度（实际中为深度的倒数，即逆深度）在这个过程中收敛，那么我们就可以确定这个未成熟地图点的三维坐标，形成了一个正常的地图点。具有三维坐标的地图点，在DSO中称为PointHessian。与FrameHessian相对，PointHessian亦记录了这个点的三维坐标，以及Hessian信息。</p>
<p>与很多其他SLAM方案不同，DSO使用单个参数描述一个地图点，即它的逆深度。而ORB-SLAM等多数方案，则会记录地图点的x,y,z三个坐标。逆深度参数化形式具有形式简单、类似高斯分布、对远处场景更为鲁棒等优点[5]，但基于逆深度参数化的Bundle adjustment，每个残差项需要比通常的BA多计算一个雅可比矩阵。为了使用逆深度，每个PointHessian必须拥有一个主导帧（host frame），说明这个点是由该帧反投影得到的。</p>
<p>于是，滑动窗口的所有信息，可以由若干个FrameHessian，加上每个帧带有的PointHessian来描述。所有的PointHessian又可以在除主导帧外的任意一帧中进行投影，形成一个残差项，记录于PointHessian::residuals中。所有的残差加起来，就构成了DSO需要求解的优化问题。当然，由于运动、遮挡的原因，并非每个点都可以成功地投影到其余任意一帧中去，于是我们还需要设置每个点的状态：有效的/被边缘化的/无效的。不同状态的点，被存储于它主导帧的pointHessians/pointHessianMarginalized/PointHessiansOut三个容器内。</p>
<p>除此之外，DSO将相机的内参、曝光参数等信息，亦作为优化变量考虑在内。相机内参由针孔相机参数fx, fy, cx, cy表达，曝光参数则由两个参数a,b描述。这部分内容在光度标定一节内。</p>
<p>后端优化部分单独具有独立的Frame, Point, Residual结构。由于DSO的优化目标是最小化能量（energy，和误差类似），所以有关后端的类均以EF开头，且与FullSystem中存储的实例一一对应，互相持有对方的指针。优化部分由EnergyFunctional类统一管理。它从FullSystem中获取所有帧和点的数据，进行优化后，再将优化结果返回。它也包含整个滑动窗口内的所有帧和点信息，负责处理实际的非线性优化矩阵运算。</p>
<h3 id="VO流程"><a href="#VO流程" class="headerlink" title="VO流程"></a>VO流程</h3><p>每当新的图像到来时，DSO将处理此图像的信息，流程如下：</p>
<p><img src="/img/cheng.png" alt></p>
<p>尽管没有解释每一步的具体用意，但可以看出DSO的大致流程。从上图可以简单总结出DSO的行为：</p>
<ul>
<li>对于非关键帧，DSO仅计算它的位姿，并用该帧图像更新每个未成熟点的深度估计；</li>
<li>后端仅处理关键帧部分的优化。除去一些内存维护操作，对每个关键帧主要做的处理有：增加新的残差项、去除错误的残差项、提取新未成熟点。</li>
<li>整个流程在一个线程内，但内部可能有多线程的操作。</li>
</ul>
<h2 id="DSO详细介绍"><a href="#DSO详细介绍" class="headerlink" title="DSO详细介绍"></a>DSO详细介绍</h2><h3 id="残差的构成与雅可比"><a href="#残差的构成与雅可比" class="headerlink" title="残差的构成与雅可比"></a>残差的构成与雅可比</h3><p>在VO过程中，DSO会维护一个滑动窗口，通常由5-7个关键帧组成，流程如前所述。DSO试图将每个先前关键帧中的地图点投影到新关键帧中，形成残差项。同时，会在新关键帧中提取未成熟点，并希望它们演变成正常地图点。在实际当中，由于运动、遮挡的原因，部分残差项会被当作outlier，最终剔除；也有部分未成熟地图点无法演化成正常地图点，最终被剔除。</p>
<p>滑动窗口内部构成了一个非线性最小二乘问题。表示成因子图（或图优化）的形式，如下所示：</p>
<p><img src="/img/xi.png" alt></p>
<p>每一个关键帧的状态为八维：六自由度的运动位姿加上两个描述光度的参数；每个地图点的状态变量为一维，即该点在主导帧（Host）里的逆深度。于是，每个残差项（或能量项E），将关联两个关键帧与一个逆深度。事实上，还有一个全局的相机内参数亦参与了优化，但未在此图中表示。</p>
<p>现在我们来考虑如何计算残差。这部分推导和LSD-SLAM的会议论文[6]，以及我的书[7]是类似的。如果读者觉得有困难，可以参照它们。</p>
<p>设相机模型由针孔模型描述，那么内参矩阵为：</p>
<p><img src="/img/hh.png" alt><br>设有两个帧，一个称为Host，一个称Target，它们各自到世界坐标的变换矩阵记为T<sub>HW</sub>,T<sub>TW</sub>，这二者又可以拆开为旋转和平移。考虑Host帧中一个像素点：</p>
<p><img src="/img/h.png" alt></p>
<p>其中 u<sub>T</sub>,v<sub>T</sub> 为该点的像素坐标，这里使用了齐次坐标以方便矩阵运算。同时，该点的逆深度为：</p>
<p><img src="/img/j.png" alt></p>
<p>其中 d<sub>H</sub> 为该点的深度值。那么，这个点在Target帧中的投影为：</p>
<p><img src="/img/a.png" alt></p>
<p>注：(i). 为方便起见，我们略去了此公式中的齐次坐标至非齐次的转换，默认它们是自动转换的；(ii). 我们定义了中间变量 p<sub>w</sub>, T<sub>TH</sub> ，即点的世界坐标，以及Host至Target的相对变换。&lt;/br&gt;<br>由此可以定义该点的残差。设Host和Target的图像分别是 I<sub>H</sub>, I<sub>T</sub> ，那么残差为：</p>
<p><img src="/img/b.png" alt></p>
<p>但是在实现中，DSO会同时估计图像的光度参数a,b，所以在计算误差时，会用到去掉光度参数之后的那个值。但是这里我们先不谈光度标定部分，所以暂时把 I<sub>H</sub>,I<sub>T</sub> 看成原始图像。</p>
<p>接下来我们要谈论雅可比。在完整DSO中，雅可比由三部分组成：</p>
<ul>
<li>图像雅可比，即图像梯度；</li>
<li>几何雅可比，描述各量相对几何量，例如旋转和平移的变化率；</li>
<li>光度雅可比，描述各个量相对光度参数的雅可比；&lt;/br&gt;<br>作者认为，几何和光度的雅可比，相对自变量来说通常是光滑函数；而图像雅可比则依赖图像数据，不够光滑；所以，在优化过程中，几何和光度的雅可比仅在迭代开始时计算一次，此后固定不变[1]。而图像雅可比则随着迭代更新。这种做法称为First-Estimate-Jacobian（FEJ），在VIO中也会经常用到[8]。它可以减小计算量、防止优化往错误的地方走太多，也可以在边缘化过程中保证零空间的维度不会降低，后者我们还要在后文继续谈。</li>
</ul>
<p>下面来看几何雅可比的具体计算。记 <img src="/img/r.png" alt> 为李代数表示的 T<sub>TW</sub> ，并定义：</p>
<p><img src="/img/c.png" alt></p>
<p>根据[7]的推导加一些变化，可知：</p>
<p><img src="/img/d.png" alt></p>
<p>再考虑对于Host帧中的逆深度<img src="/img/rho.png" alt> 之雅可比：</p>
<p><img src="/img/w.png" alt></p>
<p>显然：</p>
<p><img src="/img/q.png" alt></p>
<p>对于后者，首先记：</p>
<p><img src="/img/e.png" alt></p>
<p>那么：</p>
<p><img src="/img/f.png" alt></p>
<p>其中下标1表示取第一行，3表示第三行。于是</p>
<p><img src="/img/y.png" alt></p>
<p>最后的式子中我们重新把 <img src="/img/z.png" alt> 代回去，使得式子更加简洁。同理有：</p>
<p><img src="/img/u.png" alt><br><img src="/img/m.png" alt><br><img src="/img/n.png" alt><br><img src="/img/v.png" alt></p>
<p>值得一提的是，在DSO中，每个投影点，除了自身的位置之外，一共提供八维残差，这是为了更好利用该点的信息。这八维残差由这个点与周围几个点组成的Pattern定义，如下图所示：</p>
<p><img src="/img/2222.png" alt></p>
<p>选八个点是为了方便SSE（Super Strong Erection）（雾），其实在settings.cpp中还有许多别的Pattern。所以，在DSO的直接法中，我们实际上假设了这八个点在不同图像中保持灰度不变。并且，它们在优化中共享中间点的深度，所以也不能简单地看成八个独立的点。</p>
<h3 id="滑动窗口的维护与边缘化"><a href="#滑动窗口的维护与边缘化" class="headerlink" title="滑动窗口的维护与边缘化"></a>滑动窗口的维护与边缘化</h3><p>若干和关键帧，与它们关联的地图点组成的残差项，构成了整个滑动窗口中的内容。为了优化这些帧和点，我们会利用Gauss-Newton或Levernberg-Marquardt方法进行迭代。在迭代中，所有的残差项可以拼成一个大型的线性方程：</p>
<p><img src="/img/i.png" alt></p>
<p>其中 J,W,r 分别为拼接后的雅可比、权重和残差,<img src="/img/x.png" alt> 为整体的优化更新量。左侧可以记成： J<sup>T</sup><em>W</em>J=H ，即Hessian矩阵。这个矩阵在整个优化过程中都会一直维护于内存中。注意这种做法和ORB-SLAM2是不同的。在ORB-SLAM2的后端中，我们会不停地重构整个优化问题，求解，然后存储优化后的结果，但这个H矩阵是不会一直存在的。而在DSO中，由于H是一直维护的，所以之后的优化可以利用先前的结果，或者说，先前的优化为下一步提供了<strong>先验（Prior）</strong>。但是，为了维护这个H信息，DSO必须手动地增加/删除每一个帧和点，而不像ORB-SLAM2那样，可以无视帧和点的变化。</p>
<p>我们知道，H实际上有一个特殊的形状（<strong>箭头形矩阵，Arrow-like Matrix</strong>）[1,7,9]，如下图所示：</p>
<p><img src="/img/1.png" alt></p>
<p>众所周知，这个形状是由BA本身的结构导致的。把它的分块记为：</p>
<p><img src="/img/g.png" alt></p>
<p>那么右下角的 $\boldsymbol{C}$ 是一个对角块矩阵（因为没有结构的先验，即点——点的残差）。块的大小取决于地图点的参数化维度，在DSO中是一维，在ORB-SLAM2中是三维。接下来，在传统BA中（类似于ORB-SLAM2）的做法是这样的：</p>
<ul>
<li>通过图优化构建这个H；</li>
<li>用高斯消元法（即舒尔补）将右下角部分消元：</li>
</ul>
<p><img src="/img/p.png" alt></p>
<ul>
<li>此时方程解耦，于是先解左上部分（维度很小）；再用左上部分的结果解右下部分。</li>
</ul>
<p><img src="/img/3.png" alt></p>
<p>这个过程也称为<strong>边缘化（Marginalization）</strong>，此时我们边缘化掉了所有的点，将他们的信息归到了位姿部分中，形成了相机位姿部分的先验。这部分知识，对于每位SLAM研究者来说应当是熟知的。</p>
<p>那么在DSO中，有哪些地方用了边缘化？</p>
<p>首先，DSO的BA，也和传统BA一样，有上述步骤。因此DSO在解BA时，边缘化了所有点的信息，计算优化的更新量。然而，与传统BA不同的是，DSO的左上角部分，即公式中的<strong>B</strong> ，并非为对角块，而是有先验的。传统BA中，这部分为对角块，主要原因是不知道相机运动的先验，而DSO的滑动窗口，则通过一定手段计算了这个先验。这里的先验主要来自两个部分：</p>
<ol>
<li>边缘化某个点时，这个点的共视帧之间产生先验；</li>
<li>边缘化某个帧时，在窗口内其他帧之间产生先验；</li>
</ol>
<p>这里的“边缘化”，具体的操作和上面讲的边缘化，是一样的。也就是说，通过舒尔补，用矩阵的一部分去消元另一部分。然而实际操作的含义却有所不同。在BA的边缘化中，我们希望用边缘化加速整个问题的求解，但是解完问题后，这些帧和点仍旧是存在于窗口中的！而滑动窗口中的边缘化，是指我们不再需要这个点/这个帧。当它被边缘化时，我们将它的信息传递到了之后的先验中，而不会再利用这个点/这个帧了！请读者务必理清这层区别，否则在理解过程中会遇到问题。我们不妨将后者称为“永久边缘化”，以示区分。</p>
<p>那么DSO如何永久边缘化某个帧或点？它遵循以下几个准则：</p>
<ul>
<li>如果一个点已经不在相机视野内，就边缘化这个点；</li>
<li>如果滑动窗口内的帧数量已经超过设定阈值，那么选择其中一个帧进行边缘化；</li>
<li>当某个帧被边缘化时，以它为主导的地图点将被移除，不再参与以后的计算。否则这个点将与其他点形成结构先验，破坏BA中的稀疏结构[10]。</li>
</ul>
<p>在边缘化的过程，DSO维护了帧与帧间的先验信息（见EnergyFunctional::HM和bM），并将这些信息利用到BA的求解中去。</p>
<h3 id="零空间，FEJ"><a href="#零空间，FEJ" class="headerlink" title="零空间，FEJ"></a>零空间，FEJ</h3><p>在SLAM中，GN或LM优化过程中，状态变量事实上是存在零空间（nullspace）的。所谓零空间，就是说，如果在这个子空间内改变状态变量的值，不会影响到优化的目标函数取值。在纯视觉SLAM中，典型的零空间就是场景的绝对尺度，以及相机的绝对位姿。可以想象，如果将相机和地图同时扩大一个尺度，或者同时作一次旋转和平移，整个目标函数应该不发生改变。零空间的存在也会导致在优化过程中，线性方程的解不唯一。尽管每次迭代的步长都很小，但是时间长了，也容易让整个系统在这个零空间中游荡，令尺度发生漂移。</p>
<p>另一方面，由于边缘化的存在，如果一个点被边缘化，那它的雅可比等矩阵就要被固定于被边缘化之时刻，而其他点的雅可比还会随着时间更新，就使得整个系统中不同变量被线性化的时刻是不同的。这会导致零空间的降维——本应存在的零空间，由于线性化时刻的不同，反而消失了！而我们的估计也会变得过于乐观。</p>
<p>DSO作者提出了一个很好的例子以展现这件事情。见下图。</p>
<p><img src="/img/4.png" alt></p>
<p>在这个例子中，我们最小化 E=E<sub>1</sub>+E<sub>2</sub>=(xy-1)<sup>2</sup>+(xy-1)<sup>2</sup> ，那么显然 xy=1 这条曲线就是优化问题的最优解，正好是一维的零空间。但是，如果 E<sub>1</sub> 和 E<sub>2</sub> 在不同点上线性化，那么求得的 E 可能会让这一维的零空间消失（如图例），这时最优解变成了一个点。</p>
<p>因此，在DSO实际使用时，仅在优化的初始时刻计算几何和光度的雅可比，并让它们在随后的迭代过程中保持不变，即First-Estimate-Jacobian。FEJ强制让每个点在同一个时刻线性化，从而回避了零空间降维的问题，同时可以降低很多计算量。DSO中的每个地图点，由前面定义的pattern产生8个残差项，这些残差项也会共享FEJ。由于几何和光度函数都比较光滑，实践当中FEJ近似是十分好用的。</p>
<h3 id="其他零散的模块和算法"><a href="#其他零散的模块和算法" class="headerlink" title="其他零散的模块和算法"></a>其他零散的模块和算法</h3><p>除去上述主干以外，DSO还有一些枝节上的算法，例如：</p>
<ul>
<li>DSO是怎么初始化的？</li>
<li>DSO的CoarseTracker如何估计新帧的位姿？</li>
<li>未成熟点是如何转换到正常地图点的？<br>(TODO： 待更新）</li>
</ul>
<h2 id="光度标定"><a href="#光度标定" class="headerlink" title="光度标定"></a>光度标定</h2><p>我发现已经有一些文章介绍DSO的光度标定了[11]，所以我考虑不再重复介绍一遍了。如果需要的话我会补上。</p>
<h2 id="评述"><a href="#评述" class="headerlink" title="评述"></a>评述</h2><p>DSO的出现将直接法推进到一个相当成熟可用的地位，许多实验已表明它的精度与鲁棒性均优于现在的ORB-SLAM2，而相比之下LSD-SLAM则显然没有那么成熟。在我自己的实物相机实验中，我发现LSD-SLAM很难一次上手即通，而DSO则鲁棒的多。</p>
<p>在大部分数据集上，DSO均有较好的表现。虽然DSO要求全局曝光相机，但即使是卷帘快门的相机，只要运动不快，模糊不明显，DSO也能顺利工作。但是，如果出现明显的模糊、失真，DSO也会丢失。</p>
<p>我认为，直接法相比传统特征点法，最大的贡献在于，直接法以更整体、更优雅的方式处理了数据关联问题。特征点法需要依赖重复性较强的特征提取器，以及正确的特征匹配，才能得正确地计算相机运动。在环境纹理较好，角点较多时，这当然是可行的——不过直接法在这种环境下也能正常工作。然而，如果环境中出现了下列情况，对特征点法就不那么友善：</p>
<ul>
<li>环境中存在许多重复纹理；</li>
<li>环境中缺乏角点，出现许多边缘或光线变量不明显区域；</li>
</ul>
<p>这在实际图像中很常见，我们以道路环境为例（取自kitti）：</p>
<p><img src="/img/5.png" alt></p>
<p>显然，路面上角点甚少，仅有车道线的起始/终止处存在角点，其他地方纹理不足；天空通常也没有纹理；路旁栏杆和障碍物重复纹理非常明显。这些都是特征点法必须面对的问题，所以特征点法通常只能依赖一些车辆、行人、交通告示板来确定明显的特征匹配，这会影响整个SLAM系统的稳定性。其根本原因在于：无法找到有用的匹配点、或者容易找到错误的匹配点。例如，车道线边缘上的点外观都非常相似，栏杆附近的点则由于栏杆本身纹理重复，容易出现错配。</p>
<p>而直接法，如前所示，则并不要求一一对应的匹配。只要先前的点在当前图像当中具有合理的投影残差，我们就认为这次投影是成功的。而成功与否，主要取决于我们对地图点深度以及相机位姿的判断，并不在于图像局部看起来是什么样子。举个例子，如果用特征法或光流法追踪某个位于边缘的像素，由于沿着边缘方向图像局部很相似，所以这个匹配或追踪的结果，可能被计算成此边缘方向的另一个点——这主要是因为图像局部的相似性；而直接法的约束则来自更为整体的相机位姿，所以即使单个点无法给出足够的信息，还可以靠其他点来修正它的投影关系，从而找到正确的投影点。</p>
<p>这是一把双刃剑。直接法给予我们追踪边缘、平滑区块的能力，但同时也要付出代价——正确的直接法追踪需要有一个相当不错的初始估计，还需要一个质量较好的图像。由于DSO严重依赖于使用梯度下降的优化问题求解，而它成功的前提，是目标函数从初始值到最优值之间一直是下降的。在图像质量不佳或者相机初始位姿给的不对的情况下，这件事情往往无法得到保证，所以DSO也会丢失。</p>
<p>这种做法一个显而易见的后果是，除非存储所有的关键帧图像，否则很难利用先前建好的地图。退一步说，即使有办法存储所有关键帧的图像，那么在重用地图时，我们还需要对位姿有一个比较准确的初始估计——这通常是困难的，因为你不知道误差已经累计到了多大的程度。而在特征点法中，地图重用则相对简单。我们只需存储空间中所有的特征点和它们的特征描述，然后匹配当前图像中看到的特征，计算位姿即可。</p>
<p>我们看到，数据关联和位姿估计，在直接法中是耦合的，而在特征点法中则是解耦的。耦合的好处，在于能够更整体性地处理数据关联；而解耦的好处，在于能够在位姿不确定的情况下，仅利用图像信息去解数据关联问题。所以直接法理应更擅长求解连续图像的定位，而特征点法则更适和全局的匹配与回环检测。读者应该明了二者优缺点的来由。</p>
<p>当然DSO也不是万能的。最容易看到的缺点，就是它不是个完整的SLAM——它没有回环检测、地图重用、丢失后的重定位，而这些在实际场景中往往又是必不可少的功能。DSO的初始化部分也比较慢，当然双目或RGBD相机会容易很多。如果你想要拓展DSO的功能，首先你需要十分了解DSO的代码结构。希望本文能够起到一定的作用。</p>
<p>资料与参考文献：</p>
<p>[1]. Engel J, Koltun V, Cremers D. Direct sparse odometry<a href="https://github.com/JakobEngel/dso" target="_blank" rel="noopener">J</a>. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.</p>
<p>[2]. Forster, C.; Pizzoli, M. &amp; Scaramuzza, D., SVO: Fast semi-direct monocular visual odometry, Robotics and Automation (ICRA), 2014 IEEE International Conference on, 2014, 15-22.</p>
<p>[3]. Mur-Artal, R.; Montiel, J. &amp; Tardós, J. D. ORB-slam: a versatile and accurate monocular slam system, IEEE Transactions on Robotics, IEEE, 2015, 31, 1147-1163.</p>
<p>[4]. Bowman, S. L.; Atanasov, N.; Daniilidis, K. &amp; Pappas, G. J. Probabilistic data association for semantic SLAM Robotics and Automation (ICRA), 2017 IEEE International Conference on, 2017, 1722-1729.</p>
<p>[5]. Civera, J.; Davison, A. J. &amp; Montiel, J. M. Inverse depth parametrization for monocular SLAM, IEEE transactions on robotics, IEEE, 2008, 24, 932-945.</p>
<p>[6]. Engel, J.; Sturm, J. &amp; Cremers, D. Semi-dense visual odometry for a monocular camera Proceedings of the IEEE international conference on computer vision, 2013, 1449-1456</p>
<p>[7]. 高翔, 张涛, 刘毅, 颜沁睿, 视觉SLAM十四讲：从理论与实践,电子工业出版社, 2017</p>
<p>[8]. Leutenegger, S.; Lynen, S.; Bosse, M.; Siegwart, R. &amp; Furgale, P. Keyframe-based visual-inertial odometry using nonlinear optimization INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH, 2015, 34: 314-334</p>
<p>[9]. Barfoot, T. State Estimation for Robotics: A Matrix Lie Group Approach, Cambridge University Press, 2017</p>
<p>[10]. <a href="http://blog.csdn.net/heyijia0327/article/details/52822104" target="_blank" rel="noopener">SLAM中的marginalization 和 Schur complement</a></p>
<p>[11]. <a href="http://www.cnblogs.com/luyb/p/6077478.html" target="_blank" rel="noopener">DSO之光度标定 - 路游侠 - 博客园</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/09/19/DSO详解/" data-id="cjy09ah7x0004gdxym11djg7o" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/01/19/《黑镜之光》综合科教书籍出版计划/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          《黑镜之光》综合科教书籍出版计划
        
      </div>
    </a>
  
  
    <a href="/2017/09/18/一步步完善视觉里程计7——mapping/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">一步步完善视觉里程计7——mapping</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/robot/">robot</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/">Java</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/Android/">Android</a></li></ul></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROS/">ROS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SAE/">SAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/directions/">directions</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/donation/">donation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/goal/">goal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello/">hello</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/helloworld/">helloworld</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/robot/">robot</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ROS/" style="font-size: 10px;">ROS</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/directions/" style="font-size: 10px;">directions</a> <a href="/tags/donation/" style="font-size: 10px;">donation</a> <a href="/tags/goal/" style="font-size: 20px;">goal</a> <a href="/tags/hello/" style="font-size: 10px;">hello</a> <a href="/tags/helloworld/" style="font-size: 10px;">helloworld</a> <a href="/tags/robot/" style="font-size: 10px;">robot</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/21/角度光流/">角度光流</a>
          </li>
        
          <li>
            <a href="/2019/03/20/Nature和Science关于机器人方面的文章总结/">Nature和Science关于机器人方面的总结</a>
          </li>
        
          <li>
            <a href="/2019/03/12/警犬项目经验总结/">警犬项目经验总结</a>
          </li>
        
          <li>
            <a href="/2019/03/12/[转]ROS机器人编程：原理与应用/">『转』ROS机器人编程：原理与应用</a>
          </li>
        
          <li>
            <a href="/2018/05/07/SVO详解/">SVO详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Hhu_GFBlab<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>