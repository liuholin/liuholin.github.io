<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Nature machine intelligence | Blackant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="内容分类">
<meta property="og:type" content="article">
<meta property="og:title" content="Nature machine intelligence">
<meta property="og:url" content="http://yoursite.com/2019/03/16/Nature machine intelligence/index.html">
<meta property="og:site_name" content="Blackant">
<meta property="og:description" content="内容分类">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-03-16T15:28:23.185Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Nature machine intelligence">
<meta name="twitter:description" content="内容分类">
  
    <link rel="alternate" href="/atom.xml" title="Blackant" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Blackant</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Nature machine intelligence" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/16/Nature machine intelligence/" class="article-date">
  <time datetime="2019-03-16T02:32:14.000Z" itemprop="datePublished">2019-03-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Nature machine intelligence
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="内容分类"><a href="#内容分类" class="headerlink" title="内容分类"></a>内容分类</h1><a id="more"></a>
<h2 id="一、理论综述"><a href="#一、理论综述" class="headerlink" title="一、理论综述"></a>一、理论综述</h2><h4 id="Learnability-can-be-undecidable、"><a href="#Learnability-can-be-undecidable、" class="headerlink" title="(Learnability can be undecidable、)"></a>(Learnability can be undecidable、)</h4><h3 id="可学习性是不可决定的"><a href="#可学习性是不可决定的" class="headerlink" title="可学习性是不可决定的"></a>可学习性是不可决定的</h3><p>  The mathematical foundations of machine learning play a key role in the development of the field. They improve our understanding and provide tools for designing new learning paradigms. The advantages of mathematics, however, sometimes come with a cost. Gödel and Cohen showed, in a nutshell, that not everything is provable. Here we show that machine learning shares this fate. We describe simple scenarios where learnability cannot be proved nor refuted using the standard axioms of mathematics. Our proof is based on the fact the continuum hypothesis cannot be proved nor refuted. We show that, in some cases, a solution to the ‘estimating the maximum’ problem is equivalent to the continuum hypothesis. The main idea is to prove an equivalence between learnability and compression.</p>
<hr>
<h2 id="二、新技术、方法（提升效率，拓宽功能方面）"><a href="#二、新技术、方法（提升效率，拓宽功能方面）" class="headerlink" title="二、新技术、方法（提升效率，拓宽功能方面）"></a>二、新技术、方法（提升效率，拓宽功能方面）</h2><h4 id="Differential-game-theory-for-versatile-physical-human–robot-interaction"><a href="#Differential-game-theory-for-versatile-physical-human–robot-interaction" class="headerlink" title="Differential game theory for versatile physical human–robot interaction"></a>Differential game theory for versatile physical human–robot interaction</h4><h3 id="多用途人机交互的微分博弈论"><a href="#多用途人机交互的微分博弈论" class="headerlink" title="多用途人机交互的微分博弈论"></a>多用途人机交互的微分博弈论</h3><p>The last decades have seen a surge of robots working in contact with humans. However, until now these contact robots have made little use of the opportunities offered by physical interaction and lack a systematic methodology to produce versatile behaviours. Here, we develop an interactive robot controller able to understand the control strategy of the human user and react optimally to their movements. We demonstrate that combining an observer with a differential game theory controller can induce a stable interaction between the two partners, precisely identify each other’s control law, and allow them to successfully perform the task with minimum effort. Simulations and experiments with human subjects demonstrate these properties and illustrate how this controller can induce different representative interaction strategies.</p>
<hr>
<h4 id="Long-short-term-memory-networks-in-memristor-crossbar-arrays"><a href="#Long-short-term-memory-networks-in-memristor-crossbar-arrays" class="headerlink" title="Long short-term memory networks in memristor crossbar arrays"></a>Long short-term memory networks in memristor crossbar arrays</h4><h3 id="忆阻交叉棒阵列中的长、短期记忆网络"><a href="#忆阻交叉棒阵列中的长、短期记忆网络" class="headerlink" title="忆阻交叉棒阵列中的长、短期记忆网络"></a>忆阻交叉棒阵列中的长、短期记忆网络</h3><p>Recent breakthroughs in recurrent deep neural networks with long short-term memory (LSTM) units have led to major advances in artificial intelligence. However, state-of-the-art LSTM models with significantly increased complexity and a large number of parameters have a bottleneck in computing power resulting from both limited memory capacity and limited data communication bandwidth. Here we demonstrate experimentally that the synaptic weights shared in different time steps in an LSTM can be implemented with a memristor crossbar array, which has a small circuit footprint, can store a large number of parameters and offers in-memory computing capability that contributes to circumventing the ‘von Neumann bottleneck’. We illustrate the capability of our crossbar system as a core component in solving real-world problems in regression and classification, which shows that memristor LSTM is a promising low-power and low-latency hardware platform for edge inference.</p>
<hr>
<p>最近，在具有长短期记忆单元的深度神经网络(LSTM)方面的突破使得人工智能取得了重大进展。然而，由于有限的内存容量和有限的数据通信带宽，目前最先进的LSTM模型由于其复杂性和大量的参数而在计算能力方面存在瓶颈。在这里，我们通过实验证明，LSTM中不同时间步长共享的突触权值可以通过忆阻交叉棒阵列实现，该阵列具有较小的电路占用空间，可以存储大量参数，并提供内存计算能力，有助于绕过“冯•诺伊曼瓶颈”。我们举例说明了我们的交叉杆系统作为一个核心组件在解决实际的回归和分类问题中的能力，这表明忆阻LSTM是一个很有前途的低功耗和低延迟的边缘推理硬件平台。</p>
<h4 id="Causal-deconvolution-by-algorithmic-generative-models"><a href="#Causal-deconvolution-by-algorithmic-generative-models" class="headerlink" title="Causal deconvolution by algorithmic generative models"></a>Causal deconvolution by algorithmic generative models</h4><h3 id="因果反褶积算法生成模型"><a href="#因果反褶积算法生成模型" class="headerlink" title="因果反褶积算法生成模型"></a>因果反褶积算法生成模型</h3><p>Complex behaviour emerges from interactions between objects produced by different generating mechanisms. Yet to decode their causal origin(s) from observations remains one of the most fundamental challenges in science. Here we introduce a universal, unsupervised and parameter-free model-oriented approach, based on the seminal concept and the first principles of algorithmic probability, to decompose an observation into its most likely algorithmic generative models. Our approach uses a perturbation-based causal calculus to infer model representations. We demonstrate its ability to deconvolve interacting mechanisms regardless of whether the resultant objects are bit strings, space–time evolution diagrams, images or networks. Although this is mostly a conceptual contribution and an algorithmic framework, we also provide numerical evidence evaluating the ability of our methods to extract models from data produced by discrete dynamical systems such as cellular automata and complex networks. We think that these separating techniques can contribute to tackling the challenge of causation, thus complementing statistically oriented approaches.</p>
<h4 id="Training-deep-neural-networks-for-binary-communication-with-the-Whetstone-method"><a href="#Training-deep-neural-networks-for-binary-communication-with-the-Whetstone-method" class="headerlink" title="Training deep neural networks for binary communication with the Whetstone method"></a>Training deep neural networks for binary communication with the Whetstone method</h4><h3 id="用磨刀石法训练二进制通信的深度神经网络"><a href="#用磨刀石法训练二进制通信的深度神经网络" class="headerlink" title="用磨刀石法训练二进制通信的深度神经网络"></a>用磨刀石法训练二进制通信的深度神经网络</h3><p>The computational cost of deep neural networks presents challenges to broadly deploying these algorithms. Low-power and embedded neuromorphic processors offer potentially dramatic performance-per-watt improvements over traditional processors. However, programming these brain-inspired platforms generally requires platform-specific expertise. It is therefore difficult to achieve state-of-the-art performance on these platforms, limiting their applicability. Here we present Whetstone, a method to bridge this gap by converting deep neural networks to have discrete, binary communication. During the training process, the activation function at each layer is progressively sharpened towards a threshold activation, with limited loss in performance. Whetstone sharpened networks do not require a rate code or other spike-based coding scheme, thus producing networks comparable in timing and size to conventional artificial neural networks. We demonstrate Whetstone on a number of architectures and tasks such as image classification, autoencoders and semantic segmentation. Whetstone is currently implemented within the Keras wrapper for TensorFlow and is widely extendable.</p>
<hr>
<h2 id="三、介绍具体应用（并非普适性技术，有针对性）"><a href="#三、介绍具体应用（并非普适性技术，有针对性）" class="headerlink" title="三、介绍具体应用（并非普适性技术，有针对性）"></a>三、介绍具体应用（并非普适性技术，有针对性）</h2><h4 id="Deep-learning-cardiac-motion-analysis-for-human-survival-prediction"><a href="#Deep-learning-cardiac-motion-analysis-for-human-survival-prediction" class="headerlink" title="Deep-learning cardiac motion analysis for human survival prediction"></a>Deep-learning cardiac motion analysis for human survival prediction</h4><h3 id="心脏运动深度学习分析用于人类生存预测"><a href="#心脏运动深度学习分析用于人类生存预测" class="headerlink" title="心脏运动深度学习分析用于人类生存预测"></a>心脏运动深度学习分析用于人类生存预测</h3><p>Motion analysis is used in computer vision to understand the behaviour of moving objects in sequences of images. Optimizing the interpretation of dynamic biological systems requires accurate and precise motion tracking as well as efficient representations of high-dimensional motion trajectories so that these can be used for prediction tasks. Here we use image sequences of the heart, acquired using cardiac magnetic resonance imaging, to create time-resolved three-dimensional segmentations using a fully convolutional network trained on anatomical shape priors. This dense motion model formed the input to a supervised denoising autoencoder (4Dsurvival), which is a hybrid network consisting of an autoencoder that learns a task-specific latent code representation trained on observed outcome data, yielding a latent representation optimized for survival prediction. To handle right-censored survival outcomes, our network used a Cox partial likelihood loss function. In a study of 302 patients, the predictive accuracy (quantified by Harrell’s C-index) was significantly higher (P = 0.0012) for our model C = 0.75 (95% CI: 0.70–0.79) than the human benchmark of C = 0.59 (95% CI: 0.53–0.65). This work demonstrates how a complex computer vision task using high-dimensional medical image data can efficiently predict human survival.</p>
<hr>
<h4 id="Feedback-GAN-for-DNA-optimizes-protein-functions"><a href="#Feedback-GAN-for-DNA-optimizes-protein-functions" class="headerlink" title="Feedback GAN for DNA optimizes protein functions"></a>Feedback GAN for DNA optimizes protein functions</h4><h3 id="DNA反馈GAN优化蛋白质功能"><a href="#DNA反馈GAN优化蛋白质功能" class="headerlink" title="DNA反馈GAN优化蛋白质功能"></a>DNA反馈GAN优化蛋白质功能</h3><p>Generative adversarial networks (GANs) represent an attractive and novel approach to generate realistic data, such as genes, proteins or drugs, in synthetic biology. Here, we apply GANs to generate synthetic DNA sequences encoding for proteins of variable length. We propose a novel feedback-loop architecture, feedback GAN (FBGAN), to optimize the synthetic gene sequences for desired properties using an external function analyser. The proposed architecture also has the advantage that the analyser does not need to be differentiable. We apply the feedback-loop mechanism to two examples: generating synthetic genes coding for antimicrobial peptides, and optimizing synthetic genes for the secondary structure of their resulting peptides. A suite of metrics, calculated in silico, demonstrates that the GAN-generated proteins have desirable biophysical properties. The FBGAN architecture can also be used to optimize GAN-generated data points for useful properties in domains beyond genomics.</p>
<hr>
<h3 id="An-integrated-iterative-annotation-technique-for-easing-neural-network-training-in-medical-image-analysis"><a href="#An-integrated-iterative-annotation-technique-for-easing-neural-network-training-in-medical-image-analysis" class="headerlink" title="An integrated iterative annotation technique for easing neural network training in medical image analysis"></a>An integrated iterative annotation technique for easing neural network training in medical image analysis</h3><h3 id="一种用于医学图像分析中简化神经网络训练的集成迭代标注技术"><a href="#一种用于医学图像分析中简化神经网络训练的集成迭代标注技术" class="headerlink" title="一种用于医学图像分析中简化神经网络训练的集成迭代标注技术"></a>一种用于医学图像分析中简化神经网络训练的集成迭代标注技术</h3><p>Neural networks promise to bring robust, quantitative analysis to medical fields. However, their adoption is limited by the technicalities of training these networks and the required volume and quality of human-generated annotations. To address this gap in the field of pathology, we have created an intuitive interface for data annotation and the display of neural network predictions within a commonly used digital pathology whole-slide viewer. This strategy used a ‘human-in-the-loop’ to reduce the annotation burden. We demonstrate that segmentation of human and mouse renal micro compartments is repeatedly improved when humans interact with automatically generated annotations throughout the training process. Finally, to show the adaptability of this technique to other medical imaging fields, we demonstrate its ability to iteratively segment human prostate glands from radiology imaging data.</p>
<hr>
<h2 id="内容比例"><a href="#内容比例" class="headerlink" title="内容比例"></a>内容比例</h2><ul>
<li>理论：1</li>
<li>方法：4</li>
</ul>
<ul>
<li>应用：3</li>
</ul>
<h2 id="预计趋势与评价："><a href="#预计趋势与评价：" class="headerlink" title="预计趋势与评价："></a>预计趋势与评价：</h2><p>由于本期刊是19年1月起发行，因而考虑了两月的前言；<br><em>整理可知</em>，《自然：机器智能》将致力于将不同领域融合在一起，在人工智能、机器人、认知科学和机器学习等领域打造新的合作伙伴，进一步开发出对人类具有启发和用途的智能机器愿景。大致有<em>三个主题</em>是我们将首先关注的:<br>构建智能机器的算法和硬件的工程和研究;<br>机器智能(如深度学习系统)在其他领域(如物理、生物和医疗保健)的特定领域和主题的应用;最后研究机器智能对社会、工业和科学的影响。<br><em>其次是</em>文章允许作者在出版物中加上自己的arxiv与biorxiv的链接以供所有读者观看。（arxiv与biorxiv完全免费开放）；</p>
<p>其中我们投稿主要是冲着article去的，因而基本不需要关注三大主题中的第三个，以上的整理由于太少只能作为参考，整体来看首先是综述类文章比起主刊<em>少得多</em>，然后绝大多数是方法类、应用类，其中方法类偏向于人工智能，神经网络等，应用偏向于医学、生物类应用。</p>
<p>此外，本期刊由于相对高昂的费用，以及封闭的订阅式（难以直接在网上查看全文且订阅费用也高昂，与其他刊登计算机类文章的期刊不同）遭到了很多知名学者的抵制，他们认为这与计算机类的开放风格矛盾，个人进行投稿务必要考虑到经济的因素。<br>至少现在来看，内容上感觉偏向于理论，即便是应用也是技术而不是机器实体，与硬件关系不是很大。<br>以上是目前已刊登的全部文章，相关的文章有：</p>
<h4 id="Deep-learning-cardiac-motion-analysis-for-human-survival-prediction-1"><a href="#Deep-learning-cardiac-motion-analysis-for-human-survival-prediction-1" class="headerlink" title="Deep-learning cardiac motion analysis for human survival prediction"></a>Deep-learning cardiac motion analysis for human survival prediction</h4><h3 id="心脏运动深度学习分析用于人类生存预测-1"><a href="#心脏运动深度学习分析用于人类生存预测-1" class="headerlink" title="心脏运动深度学习分析用于人类生存预测"></a>心脏运动深度学习分析用于人类生存预测</h3><p>Motion analysis is used in computer vision to understand the behaviour of moving objects in sequences of images. Optimizing the interpretation of dynamic biological systems requires accurate and precise motion tracking as well as efficient representations of high-dimensional motion trajectories so that these can be used for prediction tasks. Here we use image sequences of the heart, acquired using cardiac magnetic resonance imaging, to create time-resolved three-dimensional segmentations using a fully convolutional network trained on anatomical shape priors. This dense motion model formed the input to a supervised denoising autoencoder (4Dsurvival), which is a hybrid network consisting of an autoencoder that learns a task-specific latent code representation trained on observed outcome data, yielding a latent representation optimized for survival prediction. To handle right-censored survival outcomes, our network used a Cox partial likelihood loss function. In a study of 302 patients, the predictive accuracy (quantified by Harrell’s C-index) was significantly higher (P = 0.0012) for our model C = 0.75 (95% CI: 0.70–0.79) than the human benchmark of C = 0.59 (95% CI: 0.53–0.65). This work demonstrates how a complex computer vision task using high-dimensional medical image data can efficiently predict human survival.</p>
<hr>
<p><em>计算机视觉相关且比较创新的应用也许可以投此刊</em></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/16/Nature machine intelligence/" data-id="cjtbn1uy8000693xy87qu20hc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2019/03/16/Science robotics/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Science robotics</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/robot/">robot</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/">Java</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/robot/Java/Android/">Android</a></li></ul></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROS/">ROS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SAE/">SAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/directions/">directions</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/donation/">donation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/goal/">goal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello/">hello</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/helloworld/">helloworld</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/robot/">robot</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ROS/" style="font-size: 10px;">ROS</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/directions/" style="font-size: 10px;">directions</a> <a href="/tags/donation/" style="font-size: 10px;">donation</a> <a href="/tags/goal/" style="font-size: 20px;">goal</a> <a href="/tags/hello/" style="font-size: 10px;">hello</a> <a href="/tags/helloworld/" style="font-size: 10px;">helloworld</a> <a href="/tags/robot/" style="font-size: 10px;">robot</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/16/Nature machine intelligence/">Nature machine intelligence</a>
          </li>
        
          <li>
            <a href="/2019/03/16/Science robotics/">Science robotics</a>
          </li>
        
          <li>
            <a href="/2019/03/12/警犬项目经验总结/">警犬项目经验总结</a>
          </li>
        
          <li>
            <a href="/2019/03/12/[转]ROS机器人编程：原理与应用/">『转』ROS机器人编程：原理与应用</a>
          </li>
        
          <li>
            <a href="/2018/05/07/SVO详解/">SVO详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Hhu_GFBlab<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>